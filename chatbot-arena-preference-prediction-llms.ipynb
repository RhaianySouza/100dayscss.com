{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rhaianycezar/chatbot-arena-preference-prediction-llms?scriptVersionId=224961737\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"ef1e0798","metadata":{"papermill":{"duration":0.00388,"end_time":"2025-02-28T10:15:49.213242","exception":false,"start_time":"2025-02-28T10:15:49.209362","status":"completed"},"tags":[]},"source":["<h1>LLM Classification Finetuning</h1>\n","<ul>\n","    <li><a href=\"#introducao\">I. Introdução</a></li>\n","    <li><a href=\"#\">II. Justificativa</a></li>\n","    <li><a href=\"#\">III. Revisão</a></li>\n","    <li><a href=\"#\">VI. Metodologia e Coleta de dados</a></li>\n","    <li><a href=\"#\">V. Modelagem</a></li>\n","    <li><a href=\"#\">VI. Resultados</a></li>\n","    <li><a href=\"#\">VII. Conclusão</a></li>\n","</ul>"]},{"cell_type":"markdown","id":"d6a035c9","metadata":{"papermill":{"duration":0.002876,"end_time":"2025-02-28T10:15:49.219623","exception":false,"start_time":"2025-02-28T10:15:49.216747","status":"completed"},"tags":[]},"source":["<h2 id=\"introducao\">I. Introdução</h2>\n","<p>Os Modelos de Linguagem de Grande Escala (LLMs) têm se tornado cada vez mais presentes em nosso cotidiano, sendo amplamente utilizados em assistentes virtuais, chatbots e outras aplicações de inteligência artificial. No entanto, um dos desafios na adoção desses modelos é garantir que suas respostas sejam alinhadas às preferências humanas, proporcionando interações mais naturais e satisfatórias. Para resolver essa questão, abordagens baseadas em Aprendizado por Reforço a partir de Feedback Humano (RLHF - Reinforcement Learning from Human Feedback) vêm sendo aplicadas, permitindo que os modelos aprendam com escolhas e preferências reais dos usuários.</p>\n","<p>Neste contexto, a competição do Kaggle Chatbot Arena Preference Prediction propõe o desafio de prever qual resposta os usuários irão preferir em um confronto direto entre dois LLMs. A competição fornece um conjunto de dados onde cada entrada contém um prompt, duas respostas geradas por diferentes modelos e a escolha do usuário. O objetivo deste projeto é desenvolver um modelo de machine learning capaz de prever essas preferências com alta precisão, contribuindo para o aprimoramento da personalização e adaptação dos LLMs às necessidades individuais dos usuários.</p>\n","<p>Além de sua relevância acadêmica e científica, este estudo tem impacto direto no desenvolvimento de sistemas de IA mais eficientes e alinhados ao comportamento humano. Modelos de linguagem que compreendem melhor as preferências dos usuários podem melhorar significativamente a experiência em aplicações comerciais, educacionais e assistenciais, reduzindo vieses e proporcionando respostas mais úteis. Assim, a pesquisa proposta visa não apenas aprimorar a interação entre humanos e máquinas, mas também contribuir para o avanço da inteligência artificial responsável.</p>"]},{"cell_type":"markdown","id":"c8b2afeb","metadata":{"papermill":{"duration":0.002877,"end_time":"2025-02-28T10:15:49.225586","exception":false,"start_time":"2025-02-28T10:15:49.222709","status":"completed"},"tags":[]},"source":["<h3>1.1 O que é LLMs?</h3>\n","<p>LLMs (Large Language Models) são modelos de inteligência artificial treinados em grandes quantidades de dados textuais para entender e gerar linguagem de forma semelhante aos humanos. Eles são baseados em redes neurais profundas, especialmente arquiteturas como os Transformers, que permitem processar e relacionar palavras em um contexto extenso (Vaswani et al., 2017). Modelos populares como <b>GPT-4 (OpenAI, 2023)</b> e <b>BERT (Devlin et al., 2018)</b> são exemplos de LLMs amplamente utilizados em chatbots, assistentes virtuais e mecanismos de busca. Esses modelos continuam evoluindo com o uso de aprendizado por reforço com feedback humano (RLHF), que os ajuda a gerar respostas mais alinhadas às preferências dos usuários (Ouyang et al., 2022).</p>"]},{"cell_type":"markdown","id":"ca7c3d91","metadata":{"papermill":{"duration":0.002874,"end_time":"2025-02-28T10:15:49.231679","exception":false,"start_time":"2025-02-28T10:15:49.228805","status":"completed"},"tags":[]},"source":["<h2>II. Justificativa</h2>\n","<p>\n","Este projeto é fundamental para melhorar a personalização e a eficácia dos Modelos de Linguagem de Grande Escala (LLMs), garantindo que suas respostas estejam alinhadas com as preferências humanas. A previsibilidade das escolhas dos usuários em interações com chatbots é essencial para tornar a experiência mais natural e satisfatória, beneficiando diversas aplicações, como assistentes virtuais, atendimento ao cliente e educação digital. Além disso, a pesquisa contribui para o avanço do Aprendizado por Reforço a partir de Feedback Humano (RLHF), permitindo a criação de modelos mais éticos e menos enviesados. Ao aprimorar a capacidade dos LLMs de compreender e se adaptar às expectativas dos usuários, este estudo também auxilia no desenvolvimento de sistemas de IA mais confiáveis e responsivos, promovendo impactos positivos tanto na academia quanto na indústria.\n","</p>"]},{"cell_type":"markdown","id":"046121dc","metadata":{"papermill":{"duration":0.002836,"end_time":"2025-02-28T10:15:49.237607","exception":false,"start_time":"2025-02-28T10:15:49.234771","status":"completed"},"tags":[]},"source":["<H2>III. Revisão Bibliografica</H2>\n","<p>\n","A revisão bibliográfica deste estudo aborda três pilares essenciais: Aprendizado por reforço a partir de feedback humano (RLHF), modelos de preferência e vieses em LLMs. Trabalhos anteriores demonstram que RLHF é uma abordagem eficaz para alinhar respostas de modelos de linguagem às preferências humanas, sendo amplamente utilizada no ajuste fino de chatbots e assistentes virtuais. Além disso, pesquisas sobre modelos de recompensa e previsão de preferências destacam a importância de técnicas de machine learning para entender padrões nas escolhas dos usuários. Por fim, estudos sobre viés em LLMs mostram que fatores como verbosidade, posição da resposta e autopromoção podem influenciar a percepção do usuário, tornando essencial a aplicação de técnicas que reduzam esses efeitos para garantir previsões mais precisas e justas.\n","</p>"]},{"cell_type":"markdown","id":"3610f89e","metadata":{"papermill":{"duration":0.002882,"end_time":"2025-02-28T10:15:49.243634","exception":false,"start_time":"2025-02-28T10:15:49.240752","status":"completed"},"tags":[]},"source":["<h2>VI. Requisitos</h2>\n","<ul>\n","    <li>Objetivo: Prever qual resposta os usuários preferirão em um confronto entre dois modelos de linguagem (LLMs).\n","Dados fornecidos: Conversas extraídas do Chatbot Arena, com prompts, respostas de dois LLMs e a escolha do usuário.</li>\n","    <li>Tarefa principal: Desenvolver um modelo de machine learning para prever as preferências humanas com alta precisão.</li> \n","    <li>Desafios envolvidos:</li>\n","    <ol>\n","    <li>Viés de posição (respostas apresentadas primeiro podem ser favorecidas).</li>\n","    <li>Viés de verbosidade (respostas mais longas podem ser percebidas como melhores).</li>\n","    <li>Viés de autopromoção (respostas que elogiam o próprio modelo podem influenciar a escolha do usuário).</li>\n","    </ol>\n","    <li>Métrica de avaliação: Perda logarítmica entre as probabilidades previstas e os valores reais da escolha do usuário.</li>\n","    <li>Formato da submissão: Arquivo CSV contendo as probabilidades de preferência para cada modelo e para empate.</li>\n","    <li>Ferramentas recomendadas: Kaggle Notebooks (ambiente com suporte a Python, Jupyter e GPUs gratuitas).</li>\n","    <li>Competição contínua: A tabela de classificação é atualizada periodicamente e inscrições com mais de dois meses são invalidadas.</li>\n","    <li>Site da competição: https://www.kaggle.com/competitions/llm-classification-finetuning</li>\n","</ul>"]},{"cell_type":"code","execution_count":1,"id":"3e408b16","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:15:49.251156Z","iopub.status.busy":"2025-02-28T10:15:49.250722Z","iopub.status.idle":"2025-02-28T10:15:54.364192Z","shell.execute_reply":"2025-02-28T10:15:54.362796Z"},"papermill":{"duration":5.119662,"end_time":"2025-02-28T10:15:54.366375","exception":false,"start_time":"2025-02-28T10:15:49.246713","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","dataTrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n","dataTest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')"]},{"cell_type":"markdown","id":"52f6ad4c","metadata":{"papermill":{"duration":0.006677,"end_time":"2025-02-28T10:15:54.376709","exception":false,"start_time":"2025-02-28T10:15:54.370032","status":"completed"},"tags":[]},"source":["<h2>V. Metodologia</h2>\n","<h3>5.1. Coleta de Dados</h3>\n","<p>Os dados utilizados neste projeto vêm da Chatbot Arena, onde usuários interagem com dois chatbots diferentes para responder a um mesmo prompt. Após receber as respostas, os usuários escolhem qual preferem.</p>\n","\n","A base de dados contém:\n","<ul>\n","    <li>ID do participante</li>\n","    <li>Modelo A e Modelo B (identificadores dos chatbots)</li>\n","    <li>Prompt (pergunta feita pelo usuário)</li>\n","    <li>Resposta A e Resposta B (respostas dos chatbots)</li>\n","    <li>Winner A, Winner B, Winner Tie (indicam qual resposta foi escolhida)</li>\n","</ul>\n","<p>Esses dados já estão coletados e prontos para serem processados e utilizados no treinamento do modelo.</p>"]},{"cell_type":"code","execution_count":2,"id":"507f2d2b","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:15:54.390177Z","iopub.status.busy":"2025-02-28T10:15:54.389819Z","iopub.status.idle":"2025-02-28T10:15:54.417757Z","shell.execute_reply":"2025-02-28T10:15:54.41659Z"},"papermill":{"duration":0.036714,"end_time":"2025-02-28T10:15:54.419324","exception":false,"start_time":"2025-02-28T10:15:54.38261","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_a</th>\n","      <th>model_b</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","      <th>winner_model_a</th>\n","      <th>winner_model_b</th>\n","      <th>winner_tie</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53567</td>\n","      <td>koala-13b</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"What is the difference between marriage lice...</td>\n","      <td>[\"A marriage license is a legal document that ...</td>\n","      <td>[\"A marriage license and a marriage certificat...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65089</td>\n","      <td>gpt-3.5-turbo-0613</td>\n","      <td>mistral-medium</td>\n","      <td>[\"explain function calling. how would you call...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>96401</td>\n","      <td>llama-2-13b-chat</td>\n","      <td>mistral-7b-instruct</td>\n","      <td>[\"How can I create a test set for a very rare ...</td>\n","      <td>[\"Creating a test set for a very rare category...</td>\n","      <td>[\"When building a classifier for a very rare c...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>koala-13b</td>\n","      <td>gpt-3.5-turbo-0314</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id             model_a              model_b  \\\n","0   30192  gpt-4-1106-preview           gpt-4-0613   \n","1   53567           koala-13b           gpt-4-0613   \n","2   65089  gpt-3.5-turbo-0613       mistral-medium   \n","3   96401    llama-2-13b-chat  mistral-7b-instruct   \n","4  198779           koala-13b   gpt-3.5-turbo-0314   \n","\n","                                              prompt  \\\n","0  [\"Is it morally right to try to have a certain...   \n","1  [\"What is the difference between marriage lice...   \n","2  [\"explain function calling. how would you call...   \n","3  [\"How can I create a test set for a very rare ...   \n","4  [\"What is the best way to travel from Tel-Aviv...   \n","\n","                                          response_a  \\\n","0  [\"The question of whether it is morally right ...   \n","1  [\"A marriage license is a legal document that ...   \n","2  [\"Function calling is the process of invoking ...   \n","3  [\"Creating a test set for a very rare category...   \n","4  [\"The best way to travel from Tel Aviv to Jeru...   \n","\n","                                          response_b  winner_model_a  \\\n","0  [\"As an AI, I don't have personal beliefs or o...               1   \n","1  [\"A marriage license and a marriage certificat...               0   \n","2  [\"Function calling is the process of invoking ...               0   \n","3  [\"When building a classifier for a very rare c...               1   \n","4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n","\n","   winner_model_b  winner_tie  \n","0               0           0  \n","1               1           0  \n","2               0           1  \n","3               0           0  \n","4               1           0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["dataTrain.head(5)"]},{"cell_type":"code","execution_count":3,"id":"ba5f00d7","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:15:54.427874Z","iopub.status.busy":"2025-02-28T10:15:54.427466Z","iopub.status.idle":"2025-02-28T10:15:54.43246Z","shell.execute_reply":"2025-02-28T10:15:54.431572Z"},"papermill":{"duration":0.01103,"end_time":"2025-02-28T10:15:54.434052","exception":false,"start_time":"2025-02-28T10:15:54.423022","status":"completed"},"tags":[]},"outputs":[],"source":["def searchModel():\n","    for j in ['model_a','model_b']:\n","        a=False\n","        for k in chatBot:\n","            if k == r[j]:\n","                a = True\n","                break\n","        if a==False:\n","            chatBot.update({r[j]:0})"]},{"cell_type":"code","execution_count":4,"id":"46e09861","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:15:54.442368Z","iopub.status.busy":"2025-02-28T10:15:54.442021Z","iopub.status.idle":"2025-02-28T10:15:54.446791Z","shell.execute_reply":"2025-02-28T10:15:54.445907Z"},"papermill":{"duration":0.01067,"end_time":"2025-02-28T10:15:54.448383","exception":false,"start_time":"2025-02-28T10:15:54.437713","status":"completed"},"tags":[]},"outputs":[],"source":["def winModel():\n","     if r['winner_model_a']==1:\n","         chatBot[r['model_a']]+=1\n","     elif r['winner_model_b']==1:\n","         chatBot[r['model_b']]+=1\n","     else:\n","         chatBot['winner_tie'] += 1\n","    \n","                "]},{"cell_type":"code","execution_count":5,"id":"0f8cdf87","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:15:54.456614Z","iopub.status.busy":"2025-02-28T10:15:54.456305Z","iopub.status.idle":"2025-02-28T10:16:06.686922Z","shell.execute_reply":"2025-02-28T10:16:06.68566Z"},"papermill":{"duration":12.236671,"end_time":"2025-02-28T10:16:06.68874","exception":false,"start_time":"2025-02-28T10:15:54.452069","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Numero de registros 57477 e 65 modelos testados\n","\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\n","A média foi de 369 caracteres e de 60 palavras\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS MODELO A =========\n","A média foi de 1377 caracteres e de 214 palavras\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\n","A média foi de 1386 caracteres e de 216 palavras\n","\n"]}],"source":["quest = {'char':0,'words':0}\n","modelA = {'char':0,'words':0}\n","modelB = {'char':0,'words':0}\n","chatBot = {'winner_tie':0}\n","index = 0\n","\n","for i,r in dataTrain.iterrows():\n","    quest['char'] += len(r['prompt'])\n","    quest['words'] += len(r['prompt'].split(' '))\n","\n","    modelA['char'] += len(r['response_a'])\n","    modelA['words'] += len(r['response_a'].split(' '))\n","\n","    modelB['char'] += len(r['response_b'])\n","    modelB['words'] += len(r['response_b'].split(' '))\n","\n","    searchModel()\n","\n","    winModel()\n","\n","\n","print(\"Numero de registros %d e %d modelos testados\\n\\n\"%(len(dataTrain), len(chatBot)))\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    quest['char']/len(dataTrain),\n","    quest['words']/len(dataTrain)))\n","\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS MODELO A =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    modelA['char']/len(dataTrain),\n","    modelA['words']/len(dataTrain)))\n","\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    modelB['char']/len(dataTrain),\n","    modelB['words']/len(dataTrain)))"]},{"cell_type":"code","execution_count":6,"id":"3f8f9492","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:16:06.697508Z","iopub.status.busy":"2025-02-28T10:16:06.69715Z","iopub.status.idle":"2025-02-28T10:16:06.704379Z","shell.execute_reply":"2025-02-28T10:16:06.703266Z"},"papermill":{"duration":0.013597,"end_time":"2025-02-28T10:16:06.706122","exception":false,"start_time":"2025-02-28T10:16:06.692525","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'winner_tie': 17761,\n"," 'gpt-4-1106-preview': 4073,\n"," 'gpt-4-0613': 2450,\n"," 'koala-13b': 561,\n"," 'gpt-3.5-turbo-0613': 2381,\n"," 'mistral-medium': 1219,\n"," 'llama-2-13b-chat': 856,\n"," 'mistral-7b-instruct': 387,\n"," 'gpt-3.5-turbo-0314': 711,\n"," 'vicuna-13b': 1244,\n"," 'gpt-4-0314': 1993,\n"," 'mixtral-8x7b-instruct-v0.1': 1196,\n"," 'gemini-pro': 465,\n"," 'claude-2.0': 956,\n"," 'vicuna-7b': 448,\n"," 'guanaco-33b': 246,\n"," 'chatglm3-6b': 157,\n"," 'openchat-3.5': 473,\n"," 'pplx-70b-online': 448,\n"," 'gpt-3.5-turbo-1106': 871,\n"," 'mpt-30b-chat': 207,\n"," 'gpt4all-13b-snoozy': 93,\n"," 'llama2-70b-steerlm-chat': 179,\n"," 'gemini-pro-dev-api': 480,\n"," 'wizardlm-70b': 588,\n"," 'claude-instant-1': 1642,\n"," 'claude-1': 1747,\n"," 'claude-2.1': 1703,\n"," 'chatglm-6b': 217,\n"," 'alpaca-13b': 356,\n"," 'gpt-4-0125-preview': 596,\n"," 'wizardlm-13b': 572,\n"," 'dolly-v2-12b': 124,\n"," 'deepseek-llm-67b-chat': 190,\n"," 'chatglm2-6b': 73,\n"," 'starling-lm-7b-alpha': 402,\n"," 'tulu-2-dpo-70b': 378,\n"," 'llama-2-7b-chat': 554,\n"," 'zephyr-7b-beta': 714,\n"," 'stablelm-tuned-alpha-7b': 132,\n"," 'oasst-pythia-12b': 343,\n"," 'vicuna-33b': 1268,\n"," 'dolphin-2.2.1-mistral-7b': 95,\n"," 'llama-2-70b-chat': 1277,\n"," 'llama-13b': 88,\n"," 'palm-2': 637,\n"," 'codellama-34b-instruct': 427,\n"," 'yi-34b-chat': 531,\n"," 'mpt-7b-chat': 213,\n"," 'fastchat-t5-3b': 196,\n"," 'qwen-14b-chat': 276,\n"," 'gpt-3.5-turbo-0125': 268,\n"," 'openhermes-2.5-mistral-7b': 280,\n"," 'qwen1.5-72b-chat': 215,\n"," 'RWKV-4-Raven-14B': 265,\n"," 'solar-10.7b-instruct-v1.0': 242,\n"," 'pplx-7b-online': 328,\n"," 'qwen1.5-4b-chat': 35,\n"," 'falcon-180b-chat': 78,\n"," 'nous-hermes-2-mixtral-8x7b-dpo': 106,\n"," 'stripedhyena-nous-7b': 206,\n"," 'zephyr-7b-alpha': 119,\n"," 'qwen1.5-7b-chat': 51,\n"," 'mistral-7b-instruct-v0.2': 27,\n"," 'openchat-3.5-0106': 63}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["chatBot"]},{"cell_type":"code","execution_count":7,"id":"dbf6e0ba","metadata":{"execution":{"iopub.execute_input":"2025-02-28T10:16:06.715186Z","iopub.status.busy":"2025-02-28T10:16:06.714863Z","iopub.status.idle":"2025-02-28T10:16:16.637356Z","shell.execute_reply":"2025-02-28T10:16:16.636424Z"},"papermill":{"duration":9.929143,"end_time":"2025-02-28T10:16:16.639275","exception":false,"start_time":"2025-02-28T10:16:06.710132","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9809560,"sourceId":86518,"sourceType":"competition"}],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":32.604785,"end_time":"2025-02-28T10:16:19.037981","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-28T10:15:46.433196","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}