{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rhaianycezar/chatbot-arena-preference-prediction-llms?scriptVersionId=224893674\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"eb44037c","metadata":{"papermill":{"duration":0.004804,"end_time":"2025-02-28T00:58:10.956529","exception":false,"start_time":"2025-02-28T00:58:10.951725","status":"completed"},"tags":[]},"source":["<h1>LLM Classification Finetuning</h1>\n","<ul>\n","    <li><a href=\"#introducao\">I. Introdução</a></li>\n","    <li><a href=\"#\">II. Justificativa</a></li>\n","    <li><a href=\"#\">III. Revisão</a></li>\n","    <li><a href=\"#\">VI. Metodologia e Coleta de dados</a></li>\n","    <li><a href=\"#\">V. Modelagem</a></li>\n","    <li><a href=\"#\">VI. Resultados</a></li>\n","    <li><a href=\"#\">VII. Conclusão</a></li>\n","</ul>"]},{"cell_type":"markdown","id":"d7e9d2d4","metadata":{"papermill":{"duration":0.002688,"end_time":"2025-02-28T00:58:10.962725","exception":false,"start_time":"2025-02-28T00:58:10.960037","status":"completed"},"tags":[]},"source":["<h2 id=\"introducao\">I. Introdução</h2>\n","<p>Os Modelos de Linguagem de Grande Escala (LLMs) têm se tornado cada vez mais presentes em nosso cotidiano, sendo amplamente utilizados em assistentes virtuais, chatbots e outras aplicações de inteligência artificial. No entanto, um dos desafios na adoção desses modelos é garantir que suas respostas sejam alinhadas às preferências humanas, proporcionando interações mais naturais e satisfatórias. Para resolver essa questão, abordagens baseadas em Aprendizado por Reforço a partir de Feedback Humano (RLHF - Reinforcement Learning from Human Feedback) vêm sendo aplicadas, permitindo que os modelos aprendam com escolhas e preferências reais dos usuários.</p>\n","<p>Neste contexto, a competição do Kaggle Chatbot Arena Preference Prediction propõe o desafio de prever qual resposta os usuários irão preferir em um confronto direto entre dois LLMs. A competição fornece um conjunto de dados onde cada entrada contém um prompt, duas respostas geradas por diferentes modelos e a escolha do usuário. O objetivo deste projeto é desenvolver um modelo de machine learning capaz de prever essas preferências com alta precisão, contribuindo para o aprimoramento da personalização e adaptação dos LLMs às necessidades individuais dos usuários.</p>\n","<p>Além de sua relevância acadêmica e científica, este estudo tem impacto direto no desenvolvimento de sistemas de IA mais eficientes e alinhados ao comportamento humano. Modelos de linguagem que compreendem melhor as preferências dos usuários podem melhorar significativamente a experiência em aplicações comerciais, educacionais e assistenciais, reduzindo vieses e proporcionando respostas mais úteis. Assim, a pesquisa proposta visa não apenas aprimorar a interação entre humanos e máquinas, mas também contribuir para o avanço da inteligência artificial responsável.</p>"]},{"cell_type":"markdown","id":"732c43fb","metadata":{"papermill":{"duration":0.002578,"end_time":"2025-02-28T00:58:10.968182","exception":false,"start_time":"2025-02-28T00:58:10.965604","status":"completed"},"tags":[]},"source":["<h3>1.1 O que é LLMs?</h3>\n","<p>LLMs (Large Language Models) são modelos de inteligência artificial treinados em grandes quantidades de dados textuais para entender e gerar linguagem de forma semelhante aos humanos. Eles são baseados em redes neurais profundas, especialmente arquiteturas como os Transformers, que permitem processar e relacionar palavras em um contexto extenso (Vaswani et al., 2017). Modelos populares como <b>GPT-4 (OpenAI, 2023)</b> e <b>BERT (Devlin et al., 2018)</b> são exemplos de LLMs amplamente utilizados em chatbots, assistentes virtuais e mecanismos de busca. Esses modelos continuam evoluindo com o uso de aprendizado por reforço com feedback humano (RLHF), que os ajuda a gerar respostas mais alinhadas às preferências dos usuários (Ouyang et al., 2022).</p>"]},{"cell_type":"markdown","id":"4309dc08","metadata":{"papermill":{"duration":0.002561,"end_time":"2025-02-28T00:58:10.973468","exception":false,"start_time":"2025-02-28T00:58:10.970907","status":"completed"},"tags":[]},"source":["<h2>II. Justificativa</h2>\n","<p>\n","Este projeto é fundamental para melhorar a personalização e a eficácia dos Modelos de Linguagem de Grande Escala (LLMs), garantindo que suas respostas estejam alinhadas com as preferências humanas. A previsibilidade das escolhas dos usuários em interações com chatbots é essencial para tornar a experiência mais natural e satisfatória, beneficiando diversas aplicações, como assistentes virtuais, atendimento ao cliente e educação digital. Além disso, a pesquisa contribui para o avanço do Aprendizado por Reforço a partir de Feedback Humano (RLHF), permitindo a criação de modelos mais éticos e menos enviesados. Ao aprimorar a capacidade dos LLMs de compreender e se adaptar às expectativas dos usuários, este estudo também auxilia no desenvolvimento de sistemas de IA mais confiáveis e responsivos, promovendo impactos positivos tanto na academia quanto na indústria.\n","</p>"]},{"cell_type":"markdown","id":"7f4ddbea","metadata":{"papermill":{"duration":0.00252,"end_time":"2025-02-28T00:58:10.978854","exception":false,"start_time":"2025-02-28T00:58:10.976334","status":"completed"},"tags":[]},"source":["<H2>III. Revisão Bibliografica</H2>\n","<p>\n","A revisão bibliográfica deste estudo aborda três pilares essenciais: Aprendizado por reforço a partir de feedback humano (RLHF), modelos de preferência e vieses em LLMs. Trabalhos anteriores demonstram que RLHF é uma abordagem eficaz para alinhar respostas de modelos de linguagem às preferências humanas, sendo amplamente utilizada no ajuste fino de chatbots e assistentes virtuais. Além disso, pesquisas sobre modelos de recompensa e previsão de preferências destacam a importância de técnicas de machine learning para entender padrões nas escolhas dos usuários. Por fim, estudos sobre viés em LLMs mostram que fatores como verbosidade, posição da resposta e autopromoção podem influenciar a percepção do usuário, tornando essencial a aplicação de técnicas que reduzam esses efeitos para garantir previsões mais precisas e justas.\n","</p>"]},{"cell_type":"markdown","id":"7db90ac8","metadata":{"papermill":{"duration":0.002535,"end_time":"2025-02-28T00:58:10.984097","exception":false,"start_time":"2025-02-28T00:58:10.981562","status":"completed"},"tags":[]},"source":["<h2>VI. Requisitos</h2>\n","<ul>\n","    <li>Objetivo: Prever qual resposta os usuários preferirão em um confronto entre dois modelos de linguagem (LLMs).\n","Dados fornecidos: Conversas extraídas do Chatbot Arena, com prompts, respostas de dois LLMs e a escolha do usuário.</li>\n","    <li>Tarefa principal: Desenvolver um modelo de machine learning para prever as preferências humanas com alta precisão.</li> \n","    <li>Desafios envolvidos:</li>\n","    <ol>\n","    <li>Viés de posição (respostas apresentadas primeiro podem ser favorecidas).</li>\n","    <li>Viés de verbosidade (respostas mais longas podem ser percebidas como melhores).</li>\n","    <li>Viés de autopromoção (respostas que elogiam o próprio modelo podem influenciar a escolha do usuário).</li>\n","    </ol>\n","    <li>Métrica de avaliação: Perda logarítmica entre as probabilidades previstas e os valores reais da escolha do usuário.</li>\n","    <li>Formato da submissão: Arquivo CSV contendo as probabilidades de preferência para cada modelo e para empate.</li>\n","    <li>Ferramentas recomendadas: Kaggle Notebooks (ambiente com suporte a Python, Jupyter e GPUs gratuitas).</li>\n","    <li>Competição contínua: A tabela de classificação é atualizada periodicamente e inscrições com mais de dois meses são invalidadas.</li>\n","    <li>Site da competição: https://www.kaggle.com/competitions/llm-classification-finetuning</li>\n","</ul>"]},{"cell_type":"code","execution_count":1,"id":"8dab9997","metadata":{"execution":{"iopub.execute_input":"2025-02-28T00:58:10.991922Z","iopub.status.busy":"2025-02-28T00:58:10.991288Z","iopub.status.idle":"2025-02-28T00:58:16.007141Z","shell.execute_reply":"2025-02-28T00:58:16.00584Z"},"papermill":{"duration":5.022342,"end_time":"2025-02-28T00:58:16.009151","exception":false,"start_time":"2025-02-28T00:58:10.986809","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","dataTrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n","dataTest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')"]},{"cell_type":"markdown","id":"102a6127","metadata":{"papermill":{"duration":0.003735,"end_time":"2025-02-28T00:58:16.016676","exception":false,"start_time":"2025-02-28T00:58:16.012941","status":"completed"},"tags":[]},"source":["<h2>V. Metodologia</h2>\n","<h3>5.1. Coleta de Dados</h3>\n","<p>Os dados utilizados neste projeto vêm da Chatbot Arena, onde usuários interagem com dois chatbots diferentes para responder a um mesmo prompt. Após receber as respostas, os usuários escolhem qual preferem.</p>\n","\n","A base de dados contém:\n","<ul>\n","    <li>ID do participante</li>\n","    <li>Modelo A e Modelo B (identificadores dos chatbots)</li>\n","    <li>Prompt (pergunta feita pelo usuário)</li>\n","    <li>Resposta A e Resposta B (respostas dos chatbots)</li>\n","    <li>Winner A, Winner B, Winner Tie (indicam qual resposta foi escolhida)</li>\n","</ul>\n","<p>Esses dados já estão coletados e prontos para serem processados e utilizados no treinamento do modelo.</p>"]},{"cell_type":"code","execution_count":2,"id":"7a61833c","metadata":{"execution":{"iopub.execute_input":"2025-02-28T00:58:16.024222Z","iopub.status.busy":"2025-02-28T00:58:16.023812Z","iopub.status.idle":"2025-02-28T00:58:16.051875Z","shell.execute_reply":"2025-02-28T00:58:16.050642Z"},"papermill":{"duration":0.033877,"end_time":"2025-02-28T00:58:16.05376","exception":false,"start_time":"2025-02-28T00:58:16.019883","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_a</th>\n","      <th>model_b</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","      <th>winner_model_a</th>\n","      <th>winner_model_b</th>\n","      <th>winner_tie</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53567</td>\n","      <td>koala-13b</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"What is the difference between marriage lice...</td>\n","      <td>[\"A marriage license is a legal document that ...</td>\n","      <td>[\"A marriage license and a marriage certificat...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65089</td>\n","      <td>gpt-3.5-turbo-0613</td>\n","      <td>mistral-medium</td>\n","      <td>[\"explain function calling. how would you call...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>96401</td>\n","      <td>llama-2-13b-chat</td>\n","      <td>mistral-7b-instruct</td>\n","      <td>[\"How can I create a test set for a very rare ...</td>\n","      <td>[\"Creating a test set for a very rare category...</td>\n","      <td>[\"When building a classifier for a very rare c...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>koala-13b</td>\n","      <td>gpt-3.5-turbo-0314</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id             model_a              model_b  \\\n","0   30192  gpt-4-1106-preview           gpt-4-0613   \n","1   53567           koala-13b           gpt-4-0613   \n","2   65089  gpt-3.5-turbo-0613       mistral-medium   \n","3   96401    llama-2-13b-chat  mistral-7b-instruct   \n","4  198779           koala-13b   gpt-3.5-turbo-0314   \n","\n","                                              prompt  \\\n","0  [\"Is it morally right to try to have a certain...   \n","1  [\"What is the difference between marriage lice...   \n","2  [\"explain function calling. how would you call...   \n","3  [\"How can I create a test set for a very rare ...   \n","4  [\"What is the best way to travel from Tel-Aviv...   \n","\n","                                          response_a  \\\n","0  [\"The question of whether it is morally right ...   \n","1  [\"A marriage license is a legal document that ...   \n","2  [\"Function calling is the process of invoking ...   \n","3  [\"Creating a test set for a very rare category...   \n","4  [\"The best way to travel from Tel Aviv to Jeru...   \n","\n","                                          response_b  winner_model_a  \\\n","0  [\"As an AI, I don't have personal beliefs or o...               1   \n","1  [\"A marriage license and a marriage certificat...               0   \n","2  [\"Function calling is the process of invoking ...               0   \n","3  [\"When building a classifier for a very rare c...               1   \n","4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n","\n","   winner_model_b  winner_tie  \n","0               0           0  \n","1               1           0  \n","2               0           1  \n","3               0           0  \n","4               1           0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["dataTrain.head(5)"]},{"cell_type":"code","execution_count":3,"id":"2f8c093c","metadata":{"execution":{"iopub.execute_input":"2025-02-28T00:58:16.061809Z","iopub.status.busy":"2025-02-28T00:58:16.061494Z","iopub.status.idle":"2025-02-28T00:58:16.06648Z","shell.execute_reply":"2025-02-28T00:58:16.065431Z"},"papermill":{"duration":0.010712,"end_time":"2025-02-28T00:58:16.068063","exception":false,"start_time":"2025-02-28T00:58:16.057351","status":"completed"},"tags":[]},"outputs":[],"source":["def searchModel():\n","    a=False\n","    for j in ['model_a','model_b']:\n","        for k in chatBot:\n","            if k == r[j]:\n","                a = True\n","                break\n","        if a==False:\n","            chatBot.append(r[j])"]},{"cell_type":"code","execution_count":4,"id":"cc23b2b3","metadata":{"execution":{"iopub.execute_input":"2025-02-28T00:58:16.075772Z","iopub.status.busy":"2025-02-28T00:58:16.075462Z","iopub.status.idle":"2025-02-28T00:58:27.591626Z","shell.execute_reply":"2025-02-28T00:58:27.590376Z"},"papermill":{"duration":11.522241,"end_time":"2025-02-28T00:58:27.593666","exception":false,"start_time":"2025-02-28T00:58:16.071425","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Numero de registros 57477 e 64 modelos testados\n","\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\n","A média foi de 369 caracteres e de 60 palavras\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS MODELO A =========\n","A média foi de 1377 caracteres e de 214 palavras\n","\n","=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\n","A média foi de 1386 caracteres e de 216 palavras\n","\n"]}],"source":["quest = {'char':0,'words':0}\n","modelA = {'char':0,'words':0}\n","modelB = {'char':0,'words':0}\n","chatBot = []\n","index = 0\n","\n","for i,r in dataTrain.iterrows():\n","    quest['char'] += len(r['prompt'])\n","    quest['words'] += len(r['prompt'].split(' '))\n","\n","    modelA['char'] += len(r['response_a'])\n","    modelA['words'] += len(r['response_a'].split(' '))\n","\n","    modelB['char'] += len(r['response_b'])\n","    modelB['words'] += len(r['response_b'].split(' '))\n","\n","    searchModel()\n","    index += 1\n","\n","\n","print(\"Numero de registros %d e %d modelos testados\\n\\n\"%(len(dataTrain), len(chatBot)))\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    quest['char']/len(dataTrain),\n","    quest['words']/len(dataTrain)))\n","\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS MODELO A =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    modelA['char']/len(dataTrain),\n","    modelA['words']/len(dataTrain)))\n","\n","print(\"=======MÉDIA DE CARACTERES E PALAVRAS POR PERGUNTAS =========\")\n","print(\"A média foi de %d caracteres e de %d palavras\\n\"%(\n","    modelB['char']/len(dataTrain),\n","    modelB['words']/len(dataTrain)))"]},{"cell_type":"code","execution_count":5,"id":"90290c67","metadata":{"execution":{"iopub.execute_input":"2025-02-28T00:58:27.602425Z","iopub.status.busy":"2025-02-28T00:58:27.601988Z","iopub.status.idle":"2025-02-28T00:58:38.14102Z","shell.execute_reply":"2025-02-28T00:58:38.139601Z"},"papermill":{"duration":10.54544,"end_time":"2025-02-28T00:58:38.142876","exception":false,"start_time":"2025-02-28T00:58:27.597436","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9809560,"sourceId":86518,"sourceType":"competition"}],"dockerImageVersionId":30918,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":32.660742,"end_time":"2025-02-28T00:58:40.694208","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-28T00:58:08.033466","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}